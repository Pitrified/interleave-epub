{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and use the app\n",
    "\n",
    "1. Create the app\n",
    "1. Pick the languages\n",
    "1. Load the NLP models\n",
    "1. Load the books\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers.pipelines import pipeline\n",
    "\n",
    "from interleave_epub.epub.epub import EPub\n",
    "from interleave_epub.interleave.constants import (\n",
    "    hug_model_name_tmpl,\n",
    "    hug_trad_cache_fol,\n",
    "    sent_model_names,\n",
    "    spa_model_cache_fol,\n",
    "    spa_model_names,\n",
    ")\n",
    "from interleave_epub.interleave.interactive import InterleaverInteractive\n",
    "from interleave_epub.nlp.cached_pipe import TranslationPipelineCache\n",
    "from interleave_epub.nlp.local_spacy_model import spacy_load_local_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ep paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epub_folder_path = Path(\"~\").expanduser() / \"snippet\" / \"datasets\" / \"ebook\"\n",
    "\n",
    "epub_paths = {\n",
    "    \"fr\": epub_folder_path / \"Gaston_Leroux_-_Le_Mystere_de_la_chambre_jaune.epub\",\n",
    "    \"en\": epub_folder_path / \"mystery_yellow_room.epub\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lts = [\"fr\", \"en\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## App\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ii = InterleaverInteractive()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the lang tags\n",
    "ii.set_lang_tag(\"fr\", \"src\")\n",
    "ii.set_lang_tag(\"en\", \"dst\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the models\n",
    "ii.load_nlp()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the books\n",
    "ii.add_book(epub_paths[\"fr\"], \"src\", \"Chambre Jaune 2\")\n",
    "ii.add_book(epub_paths[\"en\"], \"dst\", \"Yellow Room\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "an_epub = ii.epubs[\"src\"]\n",
    "a_chap = an_epub.chapters[0]\n",
    "a_par = a_chap.paragraphs[0]\n",
    "a_par\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ii.change_chapter_curr(\"forward\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ii.align_auto()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ii.aligner.compute_similarity()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "al = ii.aligners[ii.ch_id_pair_str]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.imshow(al.sim.T[::-1, :])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ii.aligner.align_auto(min_sent_len=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(al.all_good_ids_src, al.all_good_ids_dst_max, s=0.1)\n",
    "ax.plot([0, al.sent_num_src], [0, al.sent_num_dst], linewidth=0.3)\n",
    "fit_y = al.fit_func([0, al.sent_num_src])\n",
    "ax.plot([0, al.sent_num_src], fit_y)\n",
    "# ax.plot(all_good_i_rescaled, all_good_max_rescaled, linewidth=0.9)\n",
    "ax.plot(al.all_ids_src, al.all_ids_dst_max, linewidth=0.9)\n",
    "# ax.set_title(f\"Matching\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 19))\n",
    "\n",
    "# # plot the fancy ones\n",
    "# ax.plot(\n",
    "#     al.all_ids_src,\n",
    "#     al.all_ids_dst_max,\n",
    "#     marker=\"x\",\n",
    "#     color=\"r\",\n",
    "#     linestyle=\"\",\n",
    "#     alpha=0.9,\n",
    "# )\n",
    "\n",
    "# # plot the greedy ones, where they are different\n",
    "# bad_ids_src = []\n",
    "# bad_ids_dst = []\n",
    "# for i in range(len(al.all_good_ids_src)):\n",
    "#     if al.all_ids_dst_max[i] != al.all_good_ids_dst_max[i]:\n",
    "#         bad_ids_src.append(al.all_good_ids_src[i])\n",
    "#         bad_ids_dst.append(al.all_good_ids_dst_max[i])\n",
    "# ax.scatter(\n",
    "#     bad_ids_src,\n",
    "#     bad_ids_dst,\n",
    "#     marker=\"o\",\n",
    "#     color=\"r\",\n",
    "#     alpha=0.5,\n",
    "# )\n",
    "\n",
    "ax.scatter(\n",
    "    al.all_good_ids_src_rescaled,\n",
    "    al.all_good_ids_dst_max_rescaled,\n",
    "    marker=\"x\",\n",
    "    color=\"r\",\n",
    "    s=10,\n",
    "    alpha=0.8,\n",
    ")\n",
    "\n",
    "sid = 0\n",
    "for par in al.ch_src.paragraphs:\n",
    "    num_sents = len(par.sents[\"orig\"])\n",
    "    sid += num_sents\n",
    "    ax.axvline(sid, c=\"k\")\n",
    "sid = 0\n",
    "for par in al.ch_dst.paragraphs:\n",
    "    num_sents = len(par.sents[\"orig\"])\n",
    "    sid += num_sents\n",
    "    ax.axhline(sid, c=\"k\")\n",
    "\n",
    "ax.imshow(al.sim.T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ii.aligner.compute_ooo_ids()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    al.curr_id_src,\n",
    "    al.curr_id_dst_interpolate,\n",
    "    al.all_ids_dst_max[al.curr_id_src],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost done:\n",
    "\n",
    "1. Manually set the dst id\n",
    "1. Add curr src id to the fixed src ids\n",
    "1. Recompute ooo ids, skipping fixed\n",
    "1. Find the first src id to fix\n",
    "1. Get the best guess for dst\n",
    "1. Repeat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_dst_correct = 5\n",
    "ii.pick_dst_sent(id_dst_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    al.curr_id_src,\n",
    "    al.curr_id_dst_interpolate,\n",
    "    al.all_ids_dst_max[al.curr_id_src],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_src_to_dst = {\n",
    "    cs_src: cs_dst\n",
    "    for cs_src, cs_dst in zip(\n",
    "        al.all_good_ids_src_rescaled,\n",
    "        al.all_good_ids_dst_max_rescaled,\n",
    "    )\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from itertools import groupby\n",
    "\n",
    "th_consensus = 0.6\n",
    "\n",
    "# pair up sentences id in the chapter and the paragraph id they belong to\n",
    "cs_p_src_ids = [\n",
    "    {\"cs_src_id\": cs_src_id, \"par_src_id\": al.ch_src.cs_to_ps[cs_src_id][0]}\n",
    "    for cs_src_id in al.all_good_ids_src_rescaled\n",
    "]\n",
    "\n",
    "# group the pairs on the paragraphs\n",
    "# par_src_id: the src paragraph\n",
    "# cs_p_src_par_ids: the src_chap_sent_id, src_par_id pairs for this src_paragraph\n",
    "for par_src_id, cs_p_src_par_ids in groupby(cs_p_src_ids, lambda x: x[\"par_src_id\"]):\n",
    "    # the src chapter sentence ids for this src paragraph\n",
    "    cs_src_ids = list(cs_p_src[\"cs_src_id\"] for cs_p_src in cs_p_src_par_ids)\n",
    "    num_sents_src = len(cs_src_ids)\n",
    "    print(par_src_id, cs_src_ids, num_sents_src)\n",
    "\n",
    "    # search for the cs_p_src id in the good_src_rescaled dict\n",
    "    # if you find it, get the corresponding dst cs_src_id\n",
    "    # -> we are iterating over the all_good_ids_src_rescaled sooo\n",
    "    # extract all the paragraphs those sentences belong to\n",
    "    par_dst_ids = []\n",
    "    for cs_src_id in cs_src_ids:\n",
    "        if cs_src_id in good_src_to_dst:\n",
    "            # the chapter_sentence_dst id\n",
    "            cs_dst_id = good_src_to_dst[cs_src_id]\n",
    "            # dst (paragraph, ps) id\n",
    "            ps_dst_id = al.ch_dst.cs_to_ps[cs_dst_id]\n",
    "            # get only the paragraph\n",
    "            par_dst_ids.append(ps_dst_id[0])\n",
    "        else:\n",
    "            print(f\"Very unexpected, missing {cs_src_id}.\")\n",
    "\n",
    "    # if we have no good sentences we would have no group in the groupy\n",
    "    if len(par_dst_ids) == 0:\n",
    "        print(f\"Very unexpected, len=0 for {par_src_id}.\")\n",
    "        continue\n",
    "\n",
    "    # decide if there is a consensus on the paragraphs\n",
    "    par_dst_ids_count = Counter(par_dst_ids)\n",
    "    print(f\"\\t{par_dst_ids_count}\")\n",
    "    par_dst_mc = par_dst_ids_count.most_common()[0]\n",
    "    par_dst_mc_id = par_dst_mc[0]\n",
    "    par_dst_mc_count = par_dst_mc[1]\n",
    "\n",
    "    if par_dst_mc_count / num_sents_src > th_consensus:\n",
    "        print(f\"\\tMatching par {par_src_id} {par_dst_mc_id}\")\n",
    "    else:\n",
    "        print(f\"\\tNo matching. ------\")\n",
    "\n",
    "    # if len(par_dst_ids) > 3: break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par_dst_ids_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par_dst_ids_count.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par_dst_ids_count.most_common()[0][1]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('interleave-epub-QmszUGV--py3.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6684783418da4196e33b5bc6e66a97fdf8da1216b5b0b17466c551d04cad5e9a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
