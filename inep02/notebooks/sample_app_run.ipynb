{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and use the app\n",
    "\n",
    "1. Create the app\n",
    "1. Pick the languages\n",
    "1. Load the NLP models\n",
    "1. Load the books\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers.pipelines import pipeline\n",
    "\n",
    "from interleave_epub.epub.epub import EPub\n",
    "from interleave_epub.interleave.constants import (\n",
    "    hug_model_name_tmpl,\n",
    "    hug_trad_cache_fol,\n",
    "    sent_model_names,\n",
    "    spa_model_cache_fol,\n",
    "    spa_model_names,\n",
    ")\n",
    "from interleave_epub.interleave.interactive import InterleaverInteractive\n",
    "from interleave_epub.nlp.cached_pipe import TranslationPipelineCache\n",
    "from interleave_epub.nlp.local_spacy_model import spacy_load_local_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ep paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epub_folder_path = Path(\"~\").expanduser() / \"snippet\" / \"datasets\" / \"ebook\"\n",
    "\n",
    "epub_paths = {\n",
    "    \"fr\": epub_folder_path / \"Gaston_Leroux_-_Le_Mystere_de_la_chambre_jaune.epub\",\n",
    "    \"en\": epub_folder_path / \"mystery_yellow_room.epub\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lts = [\"fr\", \"en\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## App\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ii = InterleaverInteractive()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the lang tags\n",
    "ii.set_lang_tag(\"fr\", \"src\")\n",
    "ii.set_lang_tag(\"en\", \"dst\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the models\n",
    "ii.load_nlp()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the books\n",
    "ii.add_book(epub_paths[\"fr\"], \"src\", \"Chambre Jaune 2\")\n",
    "ii.add_book(epub_paths[\"en\"], \"dst\", \"Yellow Room\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "an_epub = ii.epubs[\"src\"]\n",
    "a_chap = an_epub.chapters[0]\n",
    "a_par = a_chap.paragraphs[0]\n",
    "a_par\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ii.change_chapter_curr(\"forward\")\n",
    "# ii.change_chapter_curr(\"back\")\n",
    "ii.ch_curr_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ii.align_auto()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ii.aligner.compute_similarity()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "al = ii.aligners[ii.ch_id_pair_str]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.imshow(al.sim.T[::-1, :])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ii.aligner.align_auto(min_sent_len=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(al.all_good_ids_src, al.all_good_ids_dst_max, s=0.1)\n",
    "ax.plot([0, al.sent_num_src], [0, al.sent_num_dst], linewidth=0.3)\n",
    "fit_y = al.fit_func([0, al.sent_num_src])\n",
    "ax.plot([0, al.sent_num_src], fit_y)\n",
    "# ax.plot(all_good_i_rescaled, all_good_max_rescaled, linewidth=0.9)\n",
    "ax.plot(al.all_ids_src, al.all_ids_dst_max, linewidth=0.9)\n",
    "# ax.set_title(f\"Matching\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 19))\n",
    "\n",
    "# # plot the fancy ones\n",
    "# ax.plot(\n",
    "#     al.all_ids_src,\n",
    "#     al.all_ids_dst_max,\n",
    "#     marker=\"x\",\n",
    "#     color=\"r\",\n",
    "#     linestyle=\"\",\n",
    "#     alpha=0.9,\n",
    "# )\n",
    "\n",
    "# # plot the greedy ones, where they are different\n",
    "# bad_ids_src = []\n",
    "# bad_ids_dst = []\n",
    "# for i in range(len(al.all_good_ids_src)):\n",
    "#     if al.all_ids_dst_max[i] != al.all_good_ids_dst_max[i]:\n",
    "#         bad_ids_src.append(al.all_good_ids_src[i])\n",
    "#         bad_ids_dst.append(al.all_good_ids_dst_max[i])\n",
    "# ax.scatter(\n",
    "#     bad_ids_src,\n",
    "#     bad_ids_dst,\n",
    "#     marker=\"o\",\n",
    "#     color=\"r\",\n",
    "#     alpha=0.5,\n",
    "# )\n",
    "\n",
    "ax.scatter(\n",
    "    al.all_good_ids_src_rescaled,\n",
    "    al.all_good_ids_dst_max_rescaled,\n",
    "    marker=\"x\",\n",
    "    color=\"r\",\n",
    "    s=10,\n",
    "    alpha=0.8,\n",
    ")\n",
    "\n",
    "sid = 0\n",
    "for par in al.ch_src.paragraphs:\n",
    "    num_sents = len(par.sents[\"orig\"])\n",
    "    sid += num_sents\n",
    "    ax.axvline(sid, c=\"k\")\n",
    "sid = 0\n",
    "for par in al.ch_dst.paragraphs:\n",
    "    num_sents = len(par.sents[\"orig\"])\n",
    "    sid += num_sents\n",
    "    ax.axhline(sid, c=\"k\")\n",
    "\n",
    "ax.imshow(al.sim.T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ii.aligner.compute_ooo_ids()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    al.curr_id_src,\n",
    "    al.curr_id_dst_interpolate,\n",
    "    al.all_ids_dst_max[al.curr_id_src],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost done:\n",
    "\n",
    "1. Manually set the dst id\n",
    "1. Add curr src id to the fixed src ids\n",
    "1. Recompute ooo ids, skipping fixed\n",
    "1. Find the first src id to fix\n",
    "1. Get the best guess for dst\n",
    "1. Repeat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_dst_correct = 5\n",
    "ii.pick_dst_sent(id_dst_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    al.curr_id_src,\n",
    "    al.curr_id_dst_interpolate,\n",
    "    al.all_ids_dst_max[al.curr_id_src],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In ch 1 there is something like this:\n",
    "\n",
    "```\n",
    "16 [104, ..., 115] 11\n",
    "\tCounter({13: 6, 14: 5})\n",
    "\tNo matching. ------\n",
    "19 [132, ..., 156] 24\n",
    "\tCounter({18: 12, 17: 11, 19: 1})\n",
    "\tNo matching. ------\n",
    "```\n",
    "\n",
    "that clearly matches on `13` and `17`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from itertools import groupby\n",
    "from itertools import pairwise\n",
    "\n",
    "\n",
    "def are_contiguos(it):\n",
    "    it = set(it)\n",
    "    sort_it = sorted(it)\n",
    "    # print(f\"\\t{sort_it=} {type(sort_it)}\")\n",
    "    for l, r in pairwise(sort_it):\n",
    "        # print(f\"{l=} {r=}\")\n",
    "        if r - l != 1:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "th_consensus = 0.6\n",
    "\n",
    "# pair up src and dst cs_ids\n",
    "good_cs_src_to_dst = {\n",
    "    cs_src: cs_dst\n",
    "    for cs_src, cs_dst in zip(\n",
    "        al.all_good_ids_src_rescaled,\n",
    "        al.all_good_ids_dst_max_rescaled,\n",
    "    )\n",
    "}\n",
    "\n",
    "# pair up sentences id in the chapter and the paragraph id they belong to\n",
    "cs_p_src_ids = [\n",
    "    {\"cs_src_id\": cs_src_id, \"par_src_id\": al.ch_src.cs_to_ps[cs_src_id][0]}\n",
    "    for cs_src_id in al.all_good_ids_src_rescaled\n",
    "]\n",
    "\n",
    "good_par_src_to_dst = {}\n",
    "\n",
    "# group the pairs on the paragraphs\n",
    "# par_src_id: the src paragraph\n",
    "# cs_p_src_par_ids: the src_chap_sent_id, src_par_id pairs for this src_paragraph\n",
    "for par_src_id, cs_p_src_par_ids in groupby(cs_p_src_ids, lambda x: x[\"par_src_id\"]):\n",
    "    # the src chapter sentence ids for this src paragraph\n",
    "    cs_src_ids = list(cs_p_src[\"cs_src_id\"] for cs_p_src in cs_p_src_par_ids)\n",
    "    num_sents_src = len(cs_src_ids)\n",
    "    print(par_src_id, cs_src_ids, num_sents_src)\n",
    "\n",
    "    # search for the cs_p_src id in the good_src_rescaled dict\n",
    "    # if you find it, get the corresponding dst cs_src_id\n",
    "    # -> we are iterating over the all_good_ids_src_rescaled sooo\n",
    "    # extract all the paragraphs those sentences belong to\n",
    "    par_dst_ids = []\n",
    "    for cs_src_id in cs_src_ids:\n",
    "        if cs_src_id in good_cs_src_to_dst:\n",
    "            # the chapter_sentence_dst id\n",
    "            cs_dst_id = good_cs_src_to_dst[cs_src_id]\n",
    "            # dst (paragraph, ps) id\n",
    "            ps_dst_id = al.ch_dst.cs_to_ps[cs_dst_id]\n",
    "            # get only the paragraph\n",
    "            par_dst_ids.append(ps_dst_id[0])\n",
    "        else:\n",
    "            print(f\"Very unexpected, missing {cs_src_id}.\")\n",
    "\n",
    "    # if we have no good sentences we would have no group in the groupy\n",
    "    if len(par_dst_ids) == 0:\n",
    "        print(f\"Very unexpected, len=0 for {par_src_id}.\")\n",
    "        continue\n",
    "\n",
    "    # decide if there is a consensus on the paragraphs\n",
    "    par_dst_ids_count = Counter(par_dst_ids)\n",
    "    print(f\"\\t{par_dst_ids_count}\")\n",
    "    par_dst_mc = par_dst_ids_count.most_common()[0]\n",
    "    par_dst_mc_id = par_dst_mc[0]\n",
    "    par_dst_mc_count = par_dst_mc[1]\n",
    "\n",
    "    if par_dst_mc_count / num_sents_src > th_consensus:\n",
    "        print(f\"\\tMatching par {par_src_id} {par_dst_mc_id}\")\n",
    "        good_par_src_to_dst[par_src_id] = par_dst_mc_id\n",
    "    else:\n",
    "        print(f\"\\tNo count matching. ------------------------\")\n",
    "        if are_contiguos(par_dst_ids):\n",
    "            good_par_src_to_dst[par_src_id] = par_dst_mc_id\n",
    "            print(f\"\\tContiguos matching.\")\n",
    "        else:\n",
    "            print(f\"\\tNo matching.\")\n",
    "\n",
    "    # if len(par_dst_ids) > 3: break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Could be extended to wider intervals:\n",
    "\n",
    "```\n",
    "36 41\n",
    "39 44\n",
    "missing src from 37 to 38\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "better_par_src_to_dst = {}\n",
    "\n",
    "last_src_id = 0\n",
    "last_dst_id = 0\n",
    "for par_src_id, par_dst_id in good_par_src_to_dst.items():\n",
    "    print(f\"{par_src_id} {par_dst_id}\")\n",
    "    if par_src_id > last_src_id + 1:\n",
    "        print(f\"missing src from {last_src_id+1} to {par_src_id-1}\")\n",
    "\n",
    "    # add the middle one if exactly one is missing\n",
    "    prev_par_src_id = par_src_id - 1\n",
    "    prev_par_dst_id = par_dst_id - 1\n",
    "    after_last_par_src_id = last_src_id + 1\n",
    "    after_last_par_dst_id = last_dst_id + 1\n",
    "    if (\n",
    "        prev_par_src_id == after_last_par_src_id\n",
    "        and prev_par_dst_id == after_last_par_dst_id\n",
    "    ):\n",
    "        print(f\"probable {prev_par_src_id} {after_last_par_dst_id}\")\n",
    "        better_par_src_to_dst[prev_par_src_id] = after_last_par_dst_id\n",
    "\n",
    "    # add the current one\n",
    "    better_par_src_to_dst[par_src_id] = par_dst_id\n",
    "\n",
    "    # update data\n",
    "    last_src_id = par_src_id\n",
    "    last_dst_id = par_dst_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_src_id = 0\n",
    "last_dst_id = 0\n",
    "for par_src_id, par_dst_id in better_par_src_to_dst.items():\n",
    "    print(f\"{par_src_id} {par_dst_id}\")\n",
    "\n",
    "    # check for unsorted dst paragraphs\n",
    "    if par_dst_id < last_dst_id:\n",
    "        print(\"OOO paragraphs\")\n",
    "\n",
    "    prev_par_src_id = par_src_id - 1\n",
    "    after_last_par_src_id = last_src_id + 1\n",
    "    if par_src_id > after_last_par_src_id:\n",
    "        print(f\"Missing {after_last_par_src_id} {prev_par_src_id} -> {last_dst_id+1}\")\n",
    "\n",
    "    # update data\n",
    "    last_src_id = par_src_id\n",
    "    last_dst_id = par_dst_id\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('interleave-epub-QmszUGV--py3.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6684783418da4196e33b5bc6e66a97fdf8da1216b5b0b17466c551d04cad5e9a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
